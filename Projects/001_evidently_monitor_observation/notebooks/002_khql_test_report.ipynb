{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbc99e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from evidently import Report\n",
    "from evidently.presets import DataDriftPreset, ClassificationPreset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import scorecardpy as sc\n",
    "import os, sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf00e8b",
   "metadata": {},
   "source": [
    "# reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64719e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCR_PATH = 'D:/WORK_F88/Tracy/Projects/001_evidently_monitor_observation'\n",
    "sys.path.append(SCR_PATH)\n",
    "\n",
    "from src.monitoring.utils import (load_config)\n",
    "from src.monitoring.metrics import (\n",
    "    AUCMetric,\n",
    "    GiniMetric,\n",
    "    DefaultRateMetric,\n",
    "    KSMetric,\n",
    ")\n",
    "import importlib\n",
    "import src.monitoring.pipeline\n",
    "importlib.reload(src.monitoring.pipeline)\n",
    "from src.monitoring.pipeline import GenericModelMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "monitor_churn = GenericModelMonitor('D:/WORK_F88/Tracy/Projects/001_evidently_monitor_observation/config/monitoring_config.yaml')\n",
    "\n",
    "reference_path_predict='D:/WORK_F88/Tracy/Projects/001_evidently_monitor_observation/data/training data/result_20260105_164657_20250625.parquet'\n",
    "current_path_predict='D:/WORK_F88/Tracy/Projects/001_evidently_monitor_observation/data/result_20260105_164657_20251125.parquet'\n",
    "period='2025-06'\n",
    "reference_path=r'D:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\data\\ref_all.parquet'\n",
    "current_path=r'D:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\data\\cur_all.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ae3bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c29d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_df, current_df = monitor_churn.load_data(\n",
    "        reference_path=reference_path, \n",
    "        current_path=current_path\n",
    "        )\n",
    "reference_df_pred, current_df_pred = monitor_churn.load_data(\n",
    "        reference_path=reference_path_predict, \n",
    "        current_path=current_path_predict\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4ca4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.monitoring.utils import (load_config)\n",
    "from evidently import DataDefinition\n",
    "from evidently import Dataset\n",
    "from evidently import Regression, Report\n",
    "from evidently.metrics import ValueDrift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a93d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df = pd.read_parquet(reference_path)\n",
    "curr_df = pd.read_parquet(current_path)\n",
    "curr_df = curr_df.sample(frac=1, random_state=42).reset_index()\n",
    "ref_df = ref_df.sample(frac=1, random_state=20).reset_index()\n",
    "print(f\"  Reference: {ref_df.shape}\")\n",
    "print(f\"  Current: {curr_df.shape}\")\n",
    "\n",
    "definition = DataDefinition(\n",
    "    # text_columns=categorical_columns,\n",
    "    numerical_columns=monitor_churn.numerical_columns + [monitor_churn.predict_column] + [monitor_churn.target_column],\n",
    "    categorical_columns=monitor_churn.categorical_columns,\n",
    "    # datetime_columns=monitor_churn.datetime_columns,\n",
    "    id_column=monitor_churn.id_column,\n",
    "#     timestamp=monitor_churn.timestamp_column,\n",
    "    regression=[Regression(target=monitor_churn.target_column, \n",
    "                        prediction=monitor_churn.predict_column\n",
    "                        )\n",
    "                ]\n",
    ")\n",
    "\n",
    "ref_df = Dataset.from_pandas(\n",
    "        ref_df,\n",
    "        data_definition=definition\n",
    "        )\n",
    "curr_df = Dataset.from_pandas(\n",
    "        curr_df,\n",
    "        data_definition=definition\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29c2e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "report = Report(\n",
    "    [\n",
    "        ValueDrift(column=monitor_churn.predict_column, method=\"psi\"),\n",
    "        # DataDriftPreset(\n",
    "        #     num_method=\"psi\",\n",
    "        #     cat_method=\"psi\",\n",
    "        #     include_tests=True\n",
    "        # )\n",
    "    ],\n",
    ")\n",
    "my_eval = report.run(current_data=curr_df, reference_data=ref_df)\n",
    "my_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f35e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_df = pd.read_parquet(reference_path)\n",
    "curr_df = pd.read_parquet(current_path)\n",
    "curr_df = curr_df.sort_values(\"CUSTOMER_CODE\").reset_index()\n",
    "ref_df = ref_df.sort_values(\"CUSTOMER_CODE\").reset_index()\n",
    "print(f\"  Reference: {ref_df.shape}\")\n",
    "print(f\"  Current: {curr_df.shape}\")\n",
    "\n",
    "definition = DataDefinition(\n",
    "    # text_columns=categorical_columns,\n",
    "    numerical_columns=monitor_churn.numerical_columns + [monitor_churn.predict_column] + [monitor_churn.target_column],\n",
    "    categorical_columns=monitor_churn.categorical_columns,\n",
    "    # datetime_columns=monitor_churn.datetime_columns,\n",
    "    id_column=monitor_churn.id_column,\n",
    "#     timestamp=monitor_churn.timestamp_column,\n",
    "    regression=[Regression(target=monitor_churn.target_column, \n",
    "                        prediction=monitor_churn.predict_column\n",
    "                        )\n",
    "                ]\n",
    ")\n",
    "\n",
    "ref_df = Dataset.from_pandas(\n",
    "        ref_df,\n",
    "        data_definition=definition\n",
    "        )\n",
    "curr_df = Dataset.from_pandas(\n",
    "        curr_df,\n",
    "        data_definition=definition\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3533fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "report = Report(\n",
    "    [\n",
    "        ValueDrift(column=monitor_churn.predict_column, method=\"psi\"),\n",
    "        # DataDriftPreset(\n",
    "        #     num_method=\"psi\",\n",
    "        #     cat_method=\"psi\",\n",
    "        #     include_tests=True\n",
    "        # )\n",
    "    ],\n",
    ")\n",
    "my_eval = report.run(current_data=curr_df, reference_data=ref_df)\n",
    "my_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7155e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_churn.check_data_quality(\n",
    "        reference_df=reference_df, \n",
    "        current_df=current_df,\n",
    "        period=period\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb6573c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_df.as_dataframe()['AVG_TIME_BETWEEN_2_CONTRACTS'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbb238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_churn.detect_drift(\n",
    "        reference_df=ref_df, \n",
    "        current_df=curr_df,\n",
    "        period=period\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f9358c",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3af4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_churn_1 = GenericModelMonitor('D:/WORK_F88/Tracy/Projects/001_evidently_monitor_observation/config/monitoring_config.yaml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae31c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_df_pred, current_df_pred = monitor_churn_1.load_data_perform(\n",
    "        reference_path=reference_path_predict, \n",
    "        current_path=current_path_predict\n",
    "        )\n",
    "reference_df_pred_pd = pd.read_parquet(reference_path_predict)\n",
    "current_df_pred_pd = pd.read_parquet(current_path_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa1de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = Report([\n",
    "    KSMetric(true_column=monitor_churn_1.target_column, \n",
    "             pred_column=monitor_churn_1.predict_column)\n",
    "])\n",
    "\n",
    "snapshot = report.run(current_df_pred, reference_df_pred)  # reference_dataset có thể None\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccba99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "monitor_churn_1.evaluate_performance(\n",
    "        current_df=current_df_pred, \n",
    "        reference_df=reference_df_pred, \n",
    "        period=period\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f901d491",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ff7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "reference_df, current_df = monitor_churn.load_data(\n",
    "        reference_path=reference_path_feature, \n",
    "        current_path=current_path_feature\n",
    "        )\n",
    "\n",
    "# Tab 1 - Data Quality\n",
    "result_json_1, ev_1 = monitor_churn.check_data_quality(\n",
    "    reference_df=reference_df, \n",
    "    current_df=current_df,\n",
    "    period=period\n",
    ")\n",
    "# Tab 2 - Drift\n",
    "drift_json_2, ev_2 = monitor_churn.detect_drift(\n",
    "        reference_df=reference_df, \n",
    "        current_df=current_df,\n",
    "        period=period\n",
    "        )\n",
    "reference_df_pred, current_df_pred = monitor_churn.load_data_perform(\n",
    "        reference_path=reference_path_predict, \n",
    "        current_path=current_path_predict\n",
    "        )\n",
    "# Tab 3 - Performance\n",
    "perf_json_3, ev_3 = monitor_churn.evaluate_performance(\n",
    "    current_df=current_df_pred, \n",
    "    reference_df=reference_df_pred, \n",
    "    period=period\n",
    ")\n",
    "\n",
    "# ---- Combine 3 ev reports to interactive html tabs ----\n",
    "def get_html_from_evidently(ev_report):\n",
    "    \"\"\"Return HTML content as string from Evidently report object.\"\"\"\n",
    "    import tempfile\n",
    "    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".html\")\n",
    "    ev_report.save_html(tmp.name)\n",
    "    with open(tmp.name, \"r\", encoding=\"utf-8\") as f:\n",
    "        html = f.read()\n",
    "    return html\n",
    "\n",
    "ev1_html = get_html_from_evidently(ev_1)\n",
    "ev2_html = get_html_from_evidently(ev_2)\n",
    "ev3_html = get_html_from_evidently(ev_3)\n",
    "\n",
    "tabbed_html = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <meta charset=\"utf-8\"/>\n",
    "    <title>Model Monitoring Report</title>\n",
    "    <style>\n",
    "        .tab {{\n",
    "            overflow: hidden;\n",
    "            border-bottom: 1px solid #ccc;\n",
    "            background-color: #f1f1f1;\n",
    "        }}\n",
    "\n",
    "        .tab button {{\n",
    "            background-color: inherit;\n",
    "            border: none;\n",
    "            outline: none;\n",
    "            cursor: pointer;\n",
    "            padding: 10px 20px;\n",
    "            transition: 0.3s;\n",
    "            font-size: 16px;\n",
    "        }}\n",
    "\n",
    "        .tab button.active {{\n",
    "            background-color: #e1e1e1;\n",
    "            font-weight: bold;\n",
    "        }}\n",
    "\n",
    "        .tabcontent {{\n",
    "            display: none;\n",
    "        }}\n",
    "\n",
    "        .tabcontent.active {{\n",
    "            display: block;\n",
    "        }}\n",
    "\n",
    "        /* Hide scrollbar on tab content for overlay look */\n",
    "        .tabcontent {{\n",
    "            overflow-x: auto;\n",
    "        }}\n",
    "\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <h3>Model Monitoring Summary</h3>\n",
    "    <div class=\"tab\">\n",
    "        <button class=\"tablinks active\" onclick=\"openTab(event, 'tab1')\">Data Quality</button>\n",
    "        <button class=\"tablinks\" onclick=\"openTab(event, 'tab2')\">Data Drift</button>\n",
    "        <button class=\"tablinks\" onclick=\"openTab(event, 'tab3')\">Performance</button>\n",
    "    </div>\n",
    "\n",
    "    <div id=\"tab1\" class=\"tabcontent active\">{ev1_html}</div>\n",
    "    <div id=\"tab2\" class=\"tabcontent\">{ev2_html}</div>\n",
    "    <div id=\"tab3\" class=\"tabcontent\">{ev3_html}</div>\n",
    "\n",
    "    <script>\n",
    "        function openTab(evt, tabName) {{\n",
    "            // Hide all tabcontent\n",
    "            var tabcontents = document.getElementsByClassName(\"tabcontent\");\n",
    "            for (var i = 0; i < tabcontents.length; i++) {{\n",
    "                tabcontents[i].classList.remove('active');\n",
    "            }}\n",
    "\n",
    "            // Remove active state from all buttons\n",
    "            var tablinks = document.getElementsByClassName(\"tablinks\");\n",
    "            for (var i = 0; i < tablinks.length; i++) {{\n",
    "                tablinks[i].classList.remove('active');\n",
    "            }}\n",
    "\n",
    "            // Show current tab and set active button\n",
    "            document.getElementById(tabName).classList.add('active');\n",
    "            evt.currentTarget.classList.add('active');\n",
    "        }}\n",
    "    </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "output_html_path = \"model_monitoring_report_tabs.html\"\n",
    "with open(output_html_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(tabbed_html)\n",
    "\n",
    "print(f\"Exported interactive tabbed model monitoring report to {output_html_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454e7307",
   "metadata": {},
   "source": [
    "# custom metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373c556",
   "metadata": {},
   "source": [
    "## auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from evidently import Report\n",
    "from evidently import Dataset\n",
    "from evidently import DataDefinition\n",
    "from evidently.core.report import Context\n",
    "from evidently.core.metric_types import SingleValue\n",
    "from evidently.core.metric_types import SingleValueMetric\n",
    "from evidently.core.metric_types import SingleValueCalculation\n",
    "from evidently.core.metric_types import BoundTest\n",
    "from evidently.tests import Reference, eq\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from typing import Optional\n",
    "from typing import List\n",
    "\n",
    "class AUCMetric(SingleValueMetric):\n",
    "    true_column: str\n",
    "    pred_column: str\n",
    "\n",
    "    def _default_tests(self) -> List[BoundTest]:\n",
    "        return [eq(0.5).bind_single(self.get_fingerprint())]\n",
    "\n",
    "    def _default_tests_with_reference(self) -> List[BoundTest]:\n",
    "        return [eq(Reference(relative=0.05)).bind_single(self.get_fingerprint())]\n",
    "\n",
    "# implementation\n",
    "class AUCMetricImplementation(SingleValueCalculation[AUCMetric]):\n",
    "    def calculate(self, context: Context, \n",
    "        current_data: Dataset, \n",
    "        reference_data: Optional[Dataset]\n",
    "        ) -> SingleValue:\n",
    "        y_true = current_data.column(self.metric.true_column).data\n",
    "        y_pred = current_data.column(self.metric.pred_column).data\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        result = self.result(value=auc)\n",
    "        if reference_data is not None:\n",
    "            result_ref = self.result(\n",
    "                value=roc_auc_score(reference_data.column(self.metric.true_column).data,\n",
    "                                    reference_data.column(self.metric.pred_column).data)\n",
    "                                    )\n",
    "            return result, result_ref\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "    def display_name(self) -> str:\n",
    "        return (\n",
    "            f\"AUC score for {self.metric.true_column} vs {self.metric.pred_column} \"\n",
    "        )\n",
    "\n",
    "report = Report([\n",
    "    AUCMetric(true_column=monitor_churn.target_column, \n",
    "            pred_column=monitor_churn.predict_column)\n",
    "])\n",
    "my_eval = report.run(current_data=current_df_pred, \n",
    "                    reference_data=reference_df_pred\n",
    "                    )\n",
    "my_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374329a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_eval.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec7c65",
   "metadata": {},
   "source": [
    "## woe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2976f8f",
   "metadata": {},
   "source": [
    "### utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd0d4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCR_PATH = 'D:/WORK_F88/Tracy/Projects/001_evidently_monitor_observation'\n",
    "sys.path.append(SCR_PATH)\n",
    "\n",
    "import importlib\n",
    "import src.monitoring.utils\n",
    "importlib.reload(src.monitoring.utils)\n",
    "from src.monitoring.utils import (load_config,\n",
    "                                  preprocess_for_woe_iv,\n",
    "                                  add_label_cols\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "022c1ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUSTOMER_CODE</th>\n",
       "      <th>DISB</th>\n",
       "      <th>Y_PRED_PROBA</th>\n",
       "      <th>DATE_PARTITION</th>\n",
       "      <th>AVG_TIME_BETWEEN_2_CONTRACTS</th>\n",
       "      <th>AVG_TIME_BETWEEN_3_CONTRACTS</th>\n",
       "      <th>AVG_TIME_BETWEEN_4_CONTRACTS</th>\n",
       "      <th>ASSET_TYPE</th>\n",
       "      <th>CUSTOMER_GENDER</th>\n",
       "      <th>CUSTOMER_AGE</th>\n",
       "      <th>...</th>\n",
       "      <th>NUM_RETURN_CONTRACT_6M</th>\n",
       "      <th>NUM_RETURN_CONTRACT_12M</th>\n",
       "      <th>NUM_TOPUP_CONTRACT_3M</th>\n",
       "      <th>NUM_TOPUP_CONTRACT_6M</th>\n",
       "      <th>NUM_TOPUP_CONTRACT_12M</th>\n",
       "      <th>NUM_CONTRACT_3M</th>\n",
       "      <th>NUM_CONTRACT_6M</th>\n",
       "      <th>NUM_CONTRACT_12M</th>\n",
       "      <th>DISBURSE_DATE_WID</th>\n",
       "      <th>NUM_ACTIVE_CONTRACT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1005827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>20250625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20170119.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1006510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>20250625</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20170212.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1007865</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>20250625</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20170331.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1010149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001803</td>\n",
       "      <td>20250625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20170529.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>20250625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NAM</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20171014.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529406</th>\n",
       "      <td>2599968586</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.048965</td>\n",
       "      <td>20250625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Đăng ký xe máy</td>\n",
       "      <td>NAM</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20250303.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529407</th>\n",
       "      <td>2599976980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.077295</td>\n",
       "      <td>20250625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Đăng ký xe máy</td>\n",
       "      <td>NAM</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20250215.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529408</th>\n",
       "      <td>2599984166</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042992</td>\n",
       "      <td>20250625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Đăng ký xe máy</td>\n",
       "      <td>NAM</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20250119.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529409</th>\n",
       "      <td>2599987367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051929</td>\n",
       "      <td>20250625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Đăng ký Ô tô</td>\n",
       "      <td>NỮ</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20250111.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529410</th>\n",
       "      <td>708977</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>20250625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Đăng ký xe máy</td>\n",
       "      <td>NỮ</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20220718.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>529411 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CUSTOMER_CODE  DISB  Y_PRED_PROBA  DATE_PARTITION  \\\n",
       "0            1005827   0.0      0.001803        20250625   \n",
       "1            1006510   0.0      0.001967        20250625   \n",
       "2            1007865   0.0      0.001947        20250625   \n",
       "3            1010149   0.0      0.001803        20250625   \n",
       "4            1020618   0.0      0.002118        20250625   \n",
       "...              ...   ...           ...             ...   \n",
       "529406    2599968586   1.0      0.048965        20250625   \n",
       "529407    2599976980   0.0      0.077295        20250625   \n",
       "529408    2599984166   0.0      0.042992        20250625   \n",
       "529409    2599987367   0.0      0.051929        20250625   \n",
       "529410        708977   0.0      0.005564        20250625   \n",
       "\n",
       "        AVG_TIME_BETWEEN_2_CONTRACTS  AVG_TIME_BETWEEN_3_CONTRACTS  \\\n",
       "0                                NaN                           NaN   \n",
       "1                               31.0                           NaN   \n",
       "2                               11.0                           NaN   \n",
       "3                                NaN                           NaN   \n",
       "4                                NaN                           NaN   \n",
       "...                              ...                           ...   \n",
       "529406                           NaN                           NaN   \n",
       "529407                           0.0                           NaN   \n",
       "529408                           NaN                           NaN   \n",
       "529409                           0.0                           NaN   \n",
       "529410                           0.0                           NaN   \n",
       "\n",
       "        AVG_TIME_BETWEEN_4_CONTRACTS      ASSET_TYPE CUSTOMER_GENDER  \\\n",
       "0                                NaN            None            None   \n",
       "1                                NaN            None            None   \n",
       "2                                NaN            None            None   \n",
       "3                                NaN            None            None   \n",
       "4                                NaN            None             NAM   \n",
       "...                              ...             ...             ...   \n",
       "529406                           NaN  Đăng ký xe máy             NAM   \n",
       "529407                           NaN  Đăng ký xe máy             NAM   \n",
       "529408                           NaN  Đăng ký xe máy             NAM   \n",
       "529409                           NaN    Đăng ký Ô tô              NỮ   \n",
       "529410                           NaN  Đăng ký xe máy              NỮ   \n",
       "\n",
       "        CUSTOMER_AGE  ...  NUM_RETURN_CONTRACT_6M  NUM_RETURN_CONTRACT_12M  \\\n",
       "0                NaN  ...                     0.0                      0.0   \n",
       "1                NaN  ...                     0.0                      0.0   \n",
       "2                NaN  ...                     0.0                      0.0   \n",
       "3                NaN  ...                     0.0                      0.0   \n",
       "4               31.0  ...                     0.0                      0.0   \n",
       "...              ...  ...                     ...                      ...   \n",
       "529406          29.0  ...                     0.0                      0.0   \n",
       "529407          21.0  ...                     0.0                      0.0   \n",
       "529408          31.0  ...                     0.0                      0.0   \n",
       "529409          48.0  ...                     0.0                      0.0   \n",
       "529410          54.0  ...                     0.0                      0.0   \n",
       "\n",
       "        NUM_TOPUP_CONTRACT_3M  NUM_TOPUP_CONTRACT_6M  NUM_TOPUP_CONTRACT_12M  \\\n",
       "0                         0.0                    0.0                     0.0   \n",
       "1                         0.0                    0.0                     0.0   \n",
       "2                         0.0                    0.0                     0.0   \n",
       "3                         0.0                    0.0                     0.0   \n",
       "4                         0.0                    0.0                     0.0   \n",
       "...                       ...                    ...                     ...   \n",
       "529406                    0.0                    0.0                     0.0   \n",
       "529407                    0.0                    0.0                     0.0   \n",
       "529408                    0.0                    0.0                     0.0   \n",
       "529409                    0.0                    0.0                     0.0   \n",
       "529410                    0.0                    0.0                     0.0   \n",
       "\n",
       "        NUM_CONTRACT_3M  NUM_CONTRACT_6M  NUM_CONTRACT_12M  DISBURSE_DATE_WID  \\\n",
       "0                   0.0              0.0               0.0         20170119.0   \n",
       "1                   0.0              0.0               0.0         20170212.0   \n",
       "2                   0.0              0.0               0.0         20170331.0   \n",
       "3                   0.0              0.0               0.0         20170529.0   \n",
       "4                   0.0              0.0               0.0         20171014.0   \n",
       "...                 ...              ...               ...                ...   \n",
       "529406              0.0              1.0               1.0         20250303.0   \n",
       "529407              0.0              2.0               2.0         20250215.0   \n",
       "529408              0.0              1.0               1.0         20250119.0   \n",
       "529409              0.0              2.0               2.0         20250111.0   \n",
       "529410              0.0              0.0               0.0         20220718.0   \n",
       "\n",
       "        NUM_ACTIVE_CONTRACT  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "...                     ...  \n",
       "529406                  0.0  \n",
       "529407                  0.0  \n",
       "529408                  0.0  \n",
       "529409                  0.0  \n",
       "529410                  0.0  \n",
       "\n",
       "[529411 rows x 35 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(r'D:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\data\\ref_all.parquet')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f23676de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating woe binning ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\.venv\\Lib\\site-packages\\scorecardpy\\condition_fun.py:141: UserWarning: The positive value in \"LABEL\" was replaced by 1 and negative value by 0.\n",
      "  warnings.warn(\"The positive value in \\\"{}\\\" was replaced by 1 and negative value by 0.\".format(y))\n",
      "d:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\.venv\\Lib\\site-packages\\scorecardpy\\condition_fun.py:40: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_numeric without passing `errors` and catch exceptions explicitly instead\n",
      "  datetime_cols = dat.apply(pd.to_numeric,errors='ignore').select_dtypes(object).apply(pd.to_datetime,errors='ignore').select_dtypes('datetime64').columns.tolist()\n",
      "d:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\.venv\\Lib\\site-packages\\scorecardpy\\condition_fun.py:40: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
      "  datetime_cols = dat.apply(pd.to_numeric,errors='ignore').select_dtypes(object).apply(pd.to_datetime,errors='ignore').select_dtypes('datetime64').columns.tolist()\n",
      "d:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\.venv\\Lib\\site-packages\\scorecardpy\\woebin.py:38: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .stack().replace('missing', np.nan) \\\n",
      "d:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\.venv\\Lib\\site-packages\\scorecardpy\\woebin.py:141: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  ).groupby(['variable', 'rowid', 'bin_chr'], group_keys=False).agg({'bad':sum,'good':sum})\\\n",
      "d:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\.venv\\Lib\\site-packages\\scorecardpy\\woebin.py:141: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  ).groupby(['variable', 'rowid', 'bin_chr'], group_keys=False).agg({'bad':sum,'good':sum})\\\n",
      "d:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\.venv\\Lib\\site-packages\\scorecardpy\\woebin.py:320: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  init_bin = dtm.groupby('bin', group_keys=False)['y'].agg([n0, n1])\\\n",
      "d:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\.venv\\Lib\\site-packages\\scorecardpy\\woebin.py:414: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  .agg({'good':sum, 'bad':sum}).reset_index()\\\n",
      "d:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\.venv\\Lib\\site-packages\\scorecardpy\\woebin.py:414: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  .agg({'good':sum, 'bad':sum}).reset_index()\\\n",
      "d:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\.venv\\Lib\\site-packages\\scorecardpy\\woebin.py:425: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: iv_01(x['good'], x['bad'])).reset_index(name='total_iv')\n",
      "d:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\.venv\\Lib\\site-packages\\scorecardpy\\woebin.py:442: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  binning_1bst_brk = binning_1bst_brk.groupby(['variable', 'bstbin'], group_keys=False)\\\n",
      "d:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\.venv\\Lib\\site-packages\\scorecardpy\\woebin.py:443: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  .agg({'good':sum, 'bad':sum}).reset_index().assign(bin=lambda x: x['bstbin'])\\\n",
      "d:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\.venv\\Lib\\site-packages\\scorecardpy\\woebin.py:443: FutureWarning: The provided callable <built-in function sum> is currently using SeriesGroupBy.sum. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"sum\" instead.\n",
      "  .agg({'good':sum, 'bad':sum}).reset_index().assign(bin=lambda x: x['bstbin'])\\\n"
     ]
    }
   ],
   "source": [
    "import scorecardpy as sc\n",
    "import numpy as np\n",
    "\n",
    "# Select features, excluding the target variable(s) if needed\n",
    "features = df.columns.tolist()\n",
    "\n",
    "# Assign LABEL as 'good' if DISB == 1, else 'bad' (no lambda)\n",
    "df['LABEL'] = np.where(df['DISB'] == 1, 'good', 'bad')\n",
    "\n",
    "# Example: Calculate WOE bins for a single feature (change as needed)\n",
    "bins = sc.woebin(df, y='LABEL', x=['MAX_DPD_3M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61d21e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAX_DPD_3M':      variable         bin   count  count_distr  good     bad   badprob  \\\n",
       " 0  MAX_DPD_3M     missing  484369     0.914921  5026  479343  0.989624   \n",
       " 1  MAX_DPD_3M  [-inf,inf)   45042     0.085079  4645   40397  0.896874   \n",
       " \n",
       "         woe    bin_iv  total_iv   breaks  is_special_values  \n",
       " 0  0.573595  0.230916  0.964101  missing               True  \n",
       " 1 -1.821233  0.733186  0.964101      inf              False  }"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ea1a72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "breaks_list = {}\n",
    "for feat, bin_df in bins.items():\n",
    "    if bin_df is not None and len(bin_df) > 0 and 'breaks' in bin_df.columns:\n",
    "        # Lấy breaks từ bin_df, bỏ qua 'missing' và 'special'\n",
    "        breaks = bin_df['breaks'].dropna().tolist()\n",
    "        breaks = [b for b in breaks if b not in ['missing', 'special', 'Missing', 'Special']]\n",
    "        if breaks:\n",
    "            breaks_list[feat] = breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "836903f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MAX_DPD_3M\n",
       "-1.0      24603\n",
       " 0.0       5979\n",
       " 1.0        810\n",
       " 2.0        734\n",
       "-2.0        699\n",
       "          ...  \n",
       " 104.0        1\n",
       " 92.0         1\n",
       " 132.0        1\n",
       " 102.0        1\n",
       "-41.0         1\n",
       "Name: count, Length: 136, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MAX_DPD_3M'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af9af052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AVG_TIME_BETWEEN_2_CONTRACTS': ['5.0', '45.0', '120.0', 'inf']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breaks_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19d77ad",
   "metadata": {},
   "source": [
    "### use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92724a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "634a0207",
   "metadata": {},
   "source": [
    "### old_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cd9f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from evidently.core.metric_types import (\n",
    "    SingleValue,\n",
    "    SingleValueMetric,\n",
    "    SingleValueCalculation,\n",
    "    # PlotlyGraph,\n",
    "    # PlotlyGraphData\n",
    ")\n",
    "from evidently import Dataset\n",
    "from evidently.legacy.renderers.html_widgets import plotly_figure\n",
    "\n",
    "from evidently.core.report import Context\n",
    "\n",
    "import scorecardpy as sc\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "class IVStrengthRankingMetric(SingleValueMetric):\n",
    "    target_column: str\n",
    "    features: List[str]\n",
    "\n",
    "class IVStrengthRankingMetricImplementation(SingleValueCalculation[IVStrengthRankingMetric]):\n",
    "    def calculate(\n",
    "        self,\n",
    "        context: Context,\n",
    "        current_data: Dataset,\n",
    "        reference_data: Optional[Dataset],\n",
    "    ) -> SingleValue:\n",
    "        target_col = self.metric.target_column\n",
    "        features = self.metric.features\n",
    "\n",
    "        def _get_iv_table(df: pd.DataFrame, target_col: str, features: List[str]) -> pd.DataFrame:\n",
    "            raw_cols = df.columns.tolist()\n",
    "            df = df.copy()\n",
    "            df.columns = df.columns.str.strip()\n",
    "            target_col_strip = target_col.strip()\n",
    "\n",
    "            df['LABEL'] = ['good' if x == 1 else 'bad' for x in df[target_col_strip]]\n",
    "            features = [c for c in features if c != target_col_strip and c in df.columns]\n",
    "            drop_cols = ['CUSTOMER_CODE', 'DATE_PARTITION']\n",
    "            df = df.drop(columns=[c for c in drop_cols if c in df.columns], errors=\"ignore\")\n",
    "\n",
    "            # calculate bins and woe transforms\n",
    "            bins = sc.woebin(df, y='LABEL', x=features)\n",
    "            iv_result = sc.iv(df, y='LABEL', x=features)\n",
    "            if \"iv\" not in iv_result.columns and \"info_value\" in iv_result.columns:\n",
    "                iv_result = iv_result.rename(columns={'info_value': 'iv'})\n",
    "\n",
    "            # WOE value for display in table\n",
    "            def _rank_IV(iv):\n",
    "                if iv <= 0.02:\n",
    "                    return 'Useless'\n",
    "                elif iv <= 0.1:\n",
    "                    return 'Weak'\n",
    "                elif iv <= 0.3:\n",
    "                    return 'Medium'\n",
    "                elif iv <= 0.5:\n",
    "                    return 'Strong'\n",
    "                else:\n",
    "                    return 'Suspicious'\n",
    "\n",
    "            iv_result['rank'] = iv_result['iv'].apply(_rank_IV)\n",
    "            iv_result = iv_result.sort_values('iv', ascending=False)\n",
    "            iv_result = iv_result.rename(columns={'variable': 'column', 'iv': 'IV'})\n",
    "            iv_result = iv_result[['column', 'IV', 'rank']]\n",
    "            return iv_result.reset_index(drop=True), bins\n",
    "\n",
    "        # Calculate IV tables and bins for current and reference datasets\n",
    "        cur_df = current_data.as_dataframe()\n",
    "        cur_iv_table, cur_bins = _get_iv_table(cur_df, target_col, features)\n",
    "\n",
    "        if reference_data is not None:\n",
    "            ref_df = reference_data.as_dataframe()\n",
    "            ref_iv_table, ref_bins = _get_iv_table(ref_df, target_col, features)\n",
    "\n",
    "            comp = pd.merge(ref_iv_table, cur_iv_table, on='column', suffixes=('_ref', '_cur'))\n",
    "            comp['IV_change'] = comp['IV_cur'] - comp['IV_ref']\n",
    "            comp['rank_change'] = comp['rank_cur'] + \"←\" + comp['rank_ref']\n",
    "            comp = comp[['column', 'IV_ref', 'rank_ref', 'IV_cur', 'rank_cur', 'IV_change', 'rank_change']]\n",
    "            iv_table = comp\n",
    "        else:\n",
    "            iv_table = cur_iv_table\n",
    "\n",
    "        iv_table_value = iv_table.to_dict(orient=\"records\")\n",
    "\n",
    "        # For the top variable(s), plot WOE curve (univariate)\n",
    "        # For each feature (top 1 or several), plot WOE vs bin\n",
    "        plotly_figs = []\n",
    "        top_features = iv_table['column'].values[:3] if len(iv_table) >= 3 else iv_table['column'].values\n",
    "        bins_to_plot = cur_bins  # use current data bins for the plot\n",
    "\n",
    "        for feat in top_features:\n",
    "            # get the binning dataframe for variable\n",
    "            bin_df = bins_to_plot.get(feat)\n",
    "            if bin_df is None:\n",
    "                continue\n",
    "            \n",
    "            # Prepare x: bin intervals/levels, y: woe, Count, %Bad, etc.\n",
    "            x_labels = bin_df['bin'].astype(str)\n",
    "            y_woe = bin_df['woe'].astype(float)\n",
    "            y_goodrate = bin_df['good'].astype(float)\n",
    "            y_badrate = bin_df['bad'].astype(float)\n",
    "            y_count = bin_df['count']\n",
    "\n",
    "            fig = go.Figure()\n",
    "            # WOE\n",
    "            fig.add_trace(\n",
    "                go.Bar(\n",
    "                    x=x_labels,\n",
    "                    y=y_woe,\n",
    "                    name=\"WOE\",\n",
    "                    marker_color=\"darkorange\",\n",
    "                    yaxis=\"y1\"\n",
    "                )\n",
    "            )\n",
    "            # %Bad rate\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x_labels,\n",
    "                    y=y_badrate,\n",
    "                    name=\"Bad Rate\",\n",
    "                    mode=\"lines+markers\",\n",
    "                    yaxis=\"y2\",\n",
    "                    line=dict(color=\"crimson\", dash=\"solid\"),\n",
    "                )\n",
    "            )\n",
    "            # %Good rate\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=x_labels,\n",
    "                    y=y_goodrate,\n",
    "                    name=\"Good Rate\",\n",
    "                    mode=\"lines+markers\",\n",
    "                    yaxis=\"y2\",\n",
    "                    line=dict(color=\"royalblue\", dash=\"dot\")\n",
    "                )\n",
    "            )\n",
    "            # Compose layout\n",
    "            fig.update_layout(\n",
    "                title=f\"WOE & Bad Rate by Group: {feat}\",\n",
    "                xaxis_title=\"Bin\",\n",
    "                yaxis=dict(\n",
    "                    title=\"WOE\",\n",
    "                    side=\"left\",\n",
    "                    showgrid=False\n",
    "                ),\n",
    "                yaxis2=dict(\n",
    "                    title=\"Good/Bad Rate\",\n",
    "                    overlaying=\"y\",\n",
    "                    side=\"right\",\n",
    "                    showgrid=False\n",
    "                ),\n",
    "                barmode=\"group\",\n",
    "                legend_title=\"Stat\",\n",
    "                template=\"plotly_white\",\n",
    "                margin=dict(l=40, r=40, t=60, b=40),\n",
    "                height=400\n",
    "            )\n",
    "            result = self.result(value=iv_table_value)\n",
    "            result.widget = [plotly_figure(title=self.display_name(), figure=fig)]\n",
    "\n",
    "\n",
    "        return self.result(\n",
    "            value=iv_table_value,\n",
    "            figure=plotly_figs if plotly_figs else None\n",
    "        )\n",
    "\n",
    "    def display_name(self) -> str:\n",
    "        return \"Biến xếp hạng theo IV (IV Strength & Rank by Reference, Compared with Current)\\nBiểu đồ WOE & Bad Rate của các biến lớn\"\n",
    "\n",
    "# Sử dụng trong Evidently (có hình):\n",
    "# report = Report([IVStrengthRankingMetric(target_column='BAD', features=list_of_features)])\n",
    "# result = report.run(current_data=..., reference_data=...)\n",
    "# result.json() sẽ chứa bảng IV/strength/ref/cur và figure WOE các biến top\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40580a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Reload module\n",
    "import importlib\n",
    "import src.monitoring.pipeline\n",
    "importlib.reload(src.monitoring.pipeline)\n",
    "from src.monitoring.pipeline import GenericModelMonitor\n",
    "\n",
    "# 2. Tạo lại monitor instance\n",
    "monitor_churn_1 = GenericModelMonitor('D:/WORK_F88/Tracy/Projects/001_evidently_monitor_observation/config/monitoring_config.yaml')\n",
    "\n",
    "# 3. Load lại data (TẠO DATASET MỚI)\n",
    "all_ref_df, all_cur_df = monitor_churn_1.load_data(\n",
    "    reference_path=r'D:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\notebooks\\ref_all.parquet', \n",
    "    current_path=r'D:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\notebooks\\cur_all.parquet'\n",
    ")\n",
    "\n",
    "\n",
    "report = Report([\n",
    "    IVStrengthRankingMetric(\n",
    "        target_column=monitor_churn.target_column,\n",
    "        features=monitor_churn.numerical_columns,\n",
    "    )\n",
    "])\n",
    "# 5. Chạy report\n",
    "report.run(current_data=all_cur_df, reference_data=all_ref_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e013785f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scorecardpy as sc\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "def _cal_woe_n_iv(df: pd.DataFrame, target_col: str, features: List[str], iv_threshold: float):\n",
    "    df = df.drop(columns=['CUSTOMER_CODE', 'DATE_PARTITION'], errors='ignore')\n",
    "    df['LABEL'] = ['good' if x == 1 else 'bad' for x in df[target_col]]\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if target_col not in df.columns:\n",
    "        raise KeyError(f\"Target column '{target_col}' not found. Available columns sample: {list(df.columns)[:30]}\")\n",
    "    features = [c for c in features if c != target_col]\n",
    "\n",
    "    print(f\"Features: {features}\")\n",
    "\n",
    "    bins = sc.woebin(df, y='LABEL', x=features)\n",
    "    return bins\n",
    "\n",
    "\n",
    "df = pd.read_parquet(r'D:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\notebooks\\ref_all.parquet')\n",
    "\n",
    "# Giả sử features = monitor_churn.numerical_columns (phải tồn tại ở đây)  \n",
    "# Nếu chưa có biến \"features\" đúng, cần tự định nghĩa hoặc lấy từ class monitor_churn\n",
    "\n",
    "bins= _cal_woe_n_iv(df, 'DISB', features, 0.02)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b4015",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins['N_DPD_30D_3M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b8724b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "import scorecardpy as sc\n",
    "\n",
    "from evidently.core.metric_types import SingleValue, SingleValueMetric, SingleValueCalculation\n",
    "from evidently.core.report import Context\n",
    "from evidently import Dataset\n",
    "from evidently.legacy.renderers.html_widgets import plotly_figure\n",
    "\n",
    "# Thêm logic LABEL theo rule như cell ở đầu\n",
    "def add_label_col(df: pd.DataFrame, target_col: str):\n",
    "    # Gọi trực tiếp logic phân loại LABEL good/bad như ở cell đầu file\n",
    "    df = df.copy()\n",
    "    df.columns = df.columns.str.strip()\n",
    "    if target_col not in df.columns:\n",
    "        raise KeyError(f\"Target column '{target_col}' not found. Available columns: {list(df.columns)[:30]}\")\n",
    "    # Lấy lại logic mapping\n",
    "    df['LABEL'] = ['good' if x == 1 else 'bad' for x in df[target_col]]\n",
    "    return df\n",
    "\n",
    "class BasicWOEMetric(SingleValueMetric):\n",
    "    target_column: str           # y: 0/1 (bad=1)\n",
    "    features: List[str]          # list feature columns\n",
    "    top_n: int = 50              # show top N features (by order), for readability\n",
    "\n",
    "class BasicWOEMetricImplementation(SingleValueCalculation[BasicWOEMetric]):\n",
    "    def _preprocess_df(self, df: pd.DataFrame, target: str, features: List[str]) -> tuple:\n",
    "        # Strip all column names and drop unwanted columns\n",
    "        df = df.copy()\n",
    "        df.columns = df.columns.str.strip()\n",
    "        df = df.drop(columns=[\"CUSTOMER_CODE\", \"DATE_PARTITION\"], errors=\"ignore\")\n",
    "\n",
    "        # Ensure target exists\n",
    "        if target not in df.columns:\n",
    "            raise KeyError(f\"Target column '{target}' not found after column cleanup. Available columns: {list(df.columns)[:30]}\")\n",
    "\n",
    "        # Only keep valid features and target\n",
    "        selected_features = [c for c in features if c in df.columns and c != target]\n",
    "        # Thêm LABEL cho đúng expectation scorecardpy\n",
    "        df = add_label_col(df, target)\n",
    "        df = df[selected_features + [\"LABEL\"]]\n",
    "\n",
    "        return df, selected_features\n",
    "\n",
    "    def _calc_woe(self, df, features, target):\n",
    "        # Process DataFrame before calculation\n",
    "        df_proc, used_features = self._preprocess_df(df, target, features)\n",
    "\n",
    "        # scorecardpy hates NA -> drop rows with NA in any used features\n",
    "        work = df_proc.dropna(subset=used_features)\n",
    "        # Run woebin (dùng LABEL)\n",
    "        bins = sc.woebin(work, y='LABEL', x=used_features)\n",
    "        return bins, used_features\n",
    "\n",
    "    def calculate(\n",
    "        self,\n",
    "        context: Context,\n",
    "        current_data: Dataset,\n",
    "        reference_data: Optional[Dataset],\n",
    "    ) -> SingleValue:\n",
    "        features = [c.strip() for c in self.metric.features]\n",
    "        target_col = self.metric.target_column\n",
    "\n",
    "        # ---- current_data ----\n",
    "        df_cur = current_data.as_dataframe()\n",
    "        bins_cur, use_feats_cur = self._calc_woe(df_cur, features, target_col)\n",
    "        show_feats_cur = use_feats_cur[:self.metric.top_n]\n",
    "\n",
    "        # ---- reference_data ---- \n",
    "        bins_ref = None\n",
    "        show_feats_ref = None\n",
    "        if reference_data is not None:\n",
    "            df_ref = reference_data.as_dataframe()\n",
    "            bins_ref, use_feats_ref = self._calc_woe(df_ref, features, target_col)\n",
    "            show_feats_ref = use_feats_ref[:self.metric.top_n]\n",
    "\n",
    "        widgets = []\n",
    "        # Display in two columns: left=current, right=reference\n",
    "        from plotly.subplots import make_subplots\n",
    "        top_feats = show_feats_cur[:10]  # Lấy tối đa 10 features để hiển thị\n",
    "\n",
    "        for f in top_feats:\n",
    "            bin_cur = bins_cur.get(f)\n",
    "            bin_ref = bins_ref.get(f) if (bins_ref is not None and f in bins_ref) else None\n",
    "\n",
    "            if (bin_cur is None or len(bin_cur) == 0) and (bin_ref is None or len(bin_ref) == 0):\n",
    "                continue\n",
    "\n",
    "            # find bad rate column robustly cho cả current/ref\n",
    "            def find_bad_col(df_bin):\n",
    "                if df_bin is None:\n",
    "                    return None\n",
    "                for c in [\"badprob\", \"bad_rate\", \"badrate\"]:\n",
    "                    if c in df_bin.columns:\n",
    "                        return c\n",
    "                return None\n",
    "\n",
    "            bad_col_cur = find_bad_col(bin_cur)\n",
    "            bad_col_ref = find_bad_col(bin_ref)\n",
    "\n",
    "            x_cur = bin_cur[\"bin\"].astype(str) if (bin_cur is not None and \"bin\" in bin_cur.columns) else None\n",
    "            x_ref = bin_ref[\"bin\"].astype(str) if (bin_ref is not None and \"bin\" in bin_ref.columns) else None\n",
    "\n",
    "            # Sanity check: dùng bin từ current nếu bin_ref bị thiếu hoặc khác\n",
    "            x_vals = x_cur if x_cur is not None else x_ref\n",
    "            subplot_titles = [\"Current\", \"Reference\"]\n",
    "\n",
    "            fig = make_subplots(\n",
    "                rows=1, cols=2, shared_yaxes=False,\n",
    "                subplot_titles=subplot_titles\n",
    "            )\n",
    "\n",
    "            # Vẽ current bên trái\n",
    "            if bin_cur is not None and len(bin_cur):\n",
    "                woe_cur = pd.to_numeric(bin_cur[\"woe\"], errors=\"coerce\") if \"woe\" in bin_cur.columns else None\n",
    "                badrate_cur = pd.to_numeric(bin_cur[bad_col_cur], errors=\"coerce\") if bad_col_cur else None\n",
    "\n",
    "                fig.add_trace(\n",
    "                    go.Bar(x=x_cur, y=woe_cur, name=\"WOE\", yaxis=\"y1\", marker_color=\"#1f77b4\"),\n",
    "                    row=1, col=1,\n",
    "                )\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=x_cur, y=badrate_cur, name=\"Bad rate\", mode=\"lines+markers\",\n",
    "                               marker_color=\"#ff7f0e\", yaxis=\"y2\"),\n",
    "                    row=1, col=1,\n",
    "                )\n",
    "            # Vẽ reference bên phải\n",
    "            if bin_ref is not None and len(bin_ref):\n",
    "                woe_ref = pd.to_numeric(bin_ref[\"woe\"], errors=\"coerce\") if \"woe\" in bin_ref.columns else None\n",
    "                badrate_ref = pd.to_numeric(bin_ref[bad_col_ref], errors=\"coerce\") if bad_col_ref else None\n",
    "\n",
    "                fig.add_trace(\n",
    "                    go.Bar(x=x_ref, y=woe_ref, name=\"WOE\", yaxis=\"y1\", marker_color=\"#1f77b4\", showlegend=False),\n",
    "                    row=1, col=2,\n",
    "                )\n",
    "                fig.add_trace(\n",
    "                    go.Scatter(x=x_ref, y=badrate_ref, name=\"Bad rate\", mode=\"lines+markers\",\n",
    "                               marker_color=\"#ff7f0e\", yaxis=\"y2\", showlegend=False),\n",
    "                    row=1, col=2,\n",
    "                )\n",
    "\n",
    "            # Layout cho 2 cột\n",
    "            fig.update_layout(\n",
    "                title=f\"WOE & Bad Rate by Bin — {f}\",\n",
    "                height=420,\n",
    "                margin=dict(l=40, r=40, t=60, b=60),\n",
    "            )\n",
    "            fig.update_xaxes(title_text=\"Bin\", row=1, col=1)\n",
    "            fig.update_xaxes(title_text=\"Bin\", row=1, col=2)\n",
    "            fig.update_yaxes(title_text=\"WOE\", row=1, col=1, side=\"left\")\n",
    "            fig.update_yaxes(title_text=\"WOE\", row=1, col=2, side=\"left\")\n",
    "            # Nếu muốn Bad rate sang trục phải thì cần define thêm yaxis2... \n",
    "            # (phức tạp, có thể skip cụ thể về multi-axis nếu cần)\n",
    "\n",
    "            widgets.append(plotly_figure(title=f\"WOE: {f} (Current / Reference)\", figure=fig))\n",
    "\n",
    "        # --- result ---\n",
    "        result_ref = None\n",
    "        if reference_data is not None and bins_ref is not None:\n",
    "            result_ref = self.result(value=1)\n",
    "\n",
    "        result = self.result(value=1)\n",
    "        result.widget = widgets\n",
    "\n",
    "        if reference_data is not None and result_ref is not None:\n",
    "            return result, result_ref\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "    def display_name(self) -> str:\n",
    "        return \"Basic WOE per feature\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a6e134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.monitoring.pipeline\n",
    "importlib.reload(src.monitoring.pipeline)\n",
    "from src.monitoring.pipeline import GenericModelMonitor\n",
    "\n",
    "monitor_churn_1 = GenericModelMonitor(\n",
    "    'D:/WORK_F88/Tracy/Projects/001_evidently_monitor_observation/config/monitoring_config.yaml'\n",
    ")\n",
    "\n",
    "all_ref_df, all_cur_df = monitor_churn_1.load_data(\n",
    "    reference_path=r'D:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\notebooks\\ref_all.parquet',\n",
    "    current_path=r'D:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\notebooks\\cur_all.parquet'\n",
    ")\n",
    "\n",
    "# (Optional) sanity checks: cột target + vài feature có tồn tại không\n",
    "def get_columns(obj):\n",
    "    if hasattr(obj, \"columns\"):\n",
    "        return obj.columns\n",
    "    if hasattr(obj, \"get_table_columns\"):\n",
    "        try:\n",
    "            return obj.get_table_columns()\n",
    "        except Exception:\n",
    "            pass\n",
    "    if hasattr(obj, \"_data\") and hasattr(obj._data, \"columns\"):\n",
    "        return obj._data.columns\n",
    "    return []\n",
    "\n",
    "ref_cols = get_columns(all_ref_df)\n",
    "cur_cols = get_columns(all_cur_df)\n",
    "\n",
    "print(\"Target:\", monitor_churn_1.target_column)\n",
    "print(\"Example feature count:\", len(monitor_churn_1.numerical_columns))\n",
    "print(\"Target in current?\", monitor_churn_1.target_column in cur_cols)\n",
    "print(\"Target in reference?\", monitor_churn_1.target_column in ref_cols)\n",
    "\n",
    "from evidently import Report\n",
    "\n",
    "report = Report([\n",
    "    BasicWOEMetric(\n",
    "        target_column=monitor_churn_1.target_column,     # y (thường bad=1)\n",
    "        features=monitor_churn_1.numerical_columns,      # list feature numeric\n",
    "    )\n",
    "])\n",
    "\n",
    "snapshot = report.run(current_data=all_cur_df, reference_data=all_ref_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d6a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2ef7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IVSummaryMetric(SingleValueMetric):\n",
    "    target_column: str\n",
    "    numeric_features: List[str]\n",
    "    categorical_features: List[str]\n",
    "    top_n: int = 30\n",
    "\n",
    "\n",
    "class IVSummaryMetricImplementation(SingleValueCalculation[IVSummaryMetric]):\n",
    "    def calculate(self, context: Context, current_data: Dataset, reference_data: Optional[Dataset]) -> SingleValue:\n",
    "        tgt = self.metric.target_column.strip()\n",
    "        num = self.metric.numeric_features\n",
    "        cat = self.metric.categorical_features\n",
    "\n",
    "        cur = current_data.as_dataframe().drop(columns=[\"CUSTOMER_CODE\", \"DATE_PARTITION\"], errors=\"ignore\")\n",
    "\n",
    "        # Use reference medians if possible (stable fill)\n",
    "        ref_meds = None\n",
    "        if reference_data is not None:\n",
    "            ref = reference_data.as_dataframe().drop(columns=[\"CUSTOMER_CODE\", \"DATE_PARTITION\"], errors=\"ignore\")\n",
    "            ref_prep, ref_meds = prepare_ab(ref, tgt, num, cat)\n",
    "        cur_prep, _ = prepare_ab(cur, tgt, num, cat, ref_medians=ref_meds)\n",
    "\n",
    "        # Features include numeric missing flags\n",
    "        feats = [c for c in (num + [f\"{c}_isna\" for c in num] + cat) if c in cur_prep.columns and c != tgt]\n",
    "\n",
    "        iv = sc.iv(cur_prep, y=tgt, x=feats)\n",
    "        if \"iv\" not in iv.columns and \"info_value\" in iv.columns:\n",
    "            iv = iv.rename(columns={\"info_value\": \"iv\"})\n",
    "        iv = iv.rename(columns={\"variable\": \"feature\"})[[\"feature\", \"iv\"]].sort_values(\"iv\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "        mean_iv = float(iv[\"iv\"].mean()) if len(iv) else np.nan\n",
    "        pct_iv_low = float((iv[\"iv\"] < 0.02).mean()) if len(iv) else np.nan\n",
    "\n",
    "        result = self.result(value=mean_iv)\n",
    "\n",
    "        top = iv.head(self.metric.top_n)\n",
    "        fig = go.Figure([go.Bar(x=top[\"feature\"], y=top[\"iv\"], name=\"IV\")])\n",
    "        fig.update_layout(\n",
    "            title=f\"IV Summary | mean_iv={mean_iv:.4f} | pct_iv_low={pct_iv_low:.2%}\",\n",
    "            xaxis_title=\"Feature\",\n",
    "            yaxis_title=\"IV\",\n",
    "            height=420,\n",
    "            margin=dict(l=40, r=20, t=60, b=130),\n",
    "        )\n",
    "\n",
    "        result.widget = [plotly_figure(title=\"IV Summary\", figure=fig)]\n",
    "        return result\n",
    "\n",
    "    def display_name(self) -> str:\n",
    "        return \"IV Summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96401680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.monitoring.pipeline\n",
    "importlib.reload(src.monitoring.pipeline)\n",
    "from src.monitoring.pipeline import GenericModelMonitor\n",
    "\n",
    "monitor_churn_1 = GenericModelMonitor(\n",
    "    'D:/WORK_F88/Tracy/Projects/001_evidently_monitor_observation/config/monitoring_config.yaml'\n",
    ")\n",
    "\n",
    "all_ref_df, all_cur_df = monitor_churn_1.load_data(\n",
    "    reference_path=r'D:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\notebooks\\ref_all.parquet',\n",
    "    current_path=r'D:\\WORK_F88\\Tracy\\Projects\\001_evidently_monitor_observation\\notebooks\\cur_all.parquet'\n",
    ")\n",
    "\n",
    "# (Optional) sanity checks: cột target + vài feature có tồn tại không\n",
    "def get_columns(obj):\n",
    "    # Try .columns if obj is a DataFrame\n",
    "    if hasattr(obj, \"columns\"):\n",
    "        return obj.columns\n",
    "    # If obj is a PandasDataset (Great Expectations), try .get_table_columns()\n",
    "    if hasattr(obj, \"get_table_columns\"):\n",
    "        try:\n",
    "            return obj.get_table_columns()\n",
    "        except Exception:\n",
    "            pass\n",
    "    # Try to access _data if present (sometimes in wrappers)\n",
    "    if hasattr(obj, \"_data\") and hasattr(obj._data, \"columns\"):\n",
    "        return obj._data.columns\n",
    "    return []\n",
    "\n",
    "ref_cols = get_columns(all_ref_df)\n",
    "cur_cols = get_columns(all_cur_df)\n",
    "\n",
    "print(\"Target:\", monitor_churn_1.target_column)\n",
    "print(\"Example feature count:\", len(monitor_churn_1.numerical_columns))\n",
    "print(\"Target in current?\", monitor_churn_1.target_column in cur_cols)\n",
    "print(\"Target in reference?\", monitor_churn_1.target_column in ref_cols)\n",
    "\n",
    "from evidently import Report\n",
    "\n",
    "report = Report([\n",
    "    IVSummaryMetric(\n",
    "        target_column=monitor_churn_1.target_column,     # y (thường bad=1)\n",
    "        numeric_features=monitor_churn_1.numerical_columns,      # list feature numeric\n",
    "        categorical_features=monitor_churn_1.categorical_columns\n",
    "    )\n",
    "])\n",
    "\n",
    "snapshot = report.run(current_data=all_cur_df, reference_data=all_ref_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5abcbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0307516",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
